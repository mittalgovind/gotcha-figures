<!DOCTYPE html>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB3PR2Y1TQ"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XB3PR2Y1TQ');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Circumventing Concept Erasure Methods in Text-to-Image Models</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/Highlight-Clean.css">
    <link rel="stylesheet" href="/assets/css/styles.css">

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <meta property="og:site_name" content="Circumventing Concept Erasure Methods in Text-to-Image Models" />
    <meta property="og:type" content="video.other" />
    <meta property="og:title" content="Circumventing Concept Erasure Methods in Text-to-Image Models" />
    <meta property="og:description" content="Circumventing Concept Erasure Methods in Text-to-Image Models" />
    <meta property="og:url" content="https://nyu-dice-lab.github.io/CCE/" />
    <!-- <meta property="og:image" content="/ZeroForge/docs/assets/figure3.pdf" /> -->

    <meta property="article:publisher" content="https://nyu-dice-lab.github.io/CCE/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Circumventing Concept Erasure Methods in Text-to-Image Models" />
    <meta name="twitter:description" content="We show that current concept erasure methods do not actually erase the targeted concepts." />
    <!-- <meta name="twitter:url" content="/ZeroForge/docs/assets/figure3.pdf" />
    <meta name="twitter:image" content="/ZeroForge/docs/assets/figure3.pdf" /> -->
    <!-- <meta name="twitter:site" content="" /> -->

    <!-- <script src="assets/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script> -->
    <style>
        .banner {
        display: flex;
        justify-content: center; /* Center the banner horizontally */
        }

        .gif-banner {
        display: flex; /* Use flexbox to align items horizontally */
        align-items: center; /* Center the GIFs vertically */
        gap: -5px; /* Remove the whitespace between GIFs */
        }
        
        .gif-banner img {
        flex-shrink: 0; /* Prevent the GIFs from shrinking further */
        width: auto; /* Allow the GIFs to scale proportionally */
        height: 160px; /* Adjust the height as needed */
        }

        .gif-caption {
        text-align: center;
        margin-top: 5px; /* Adjust the spacing between the GIF and the caption */
        }
    </style>
</head>

<body>
    <div class="highlight-clean" style="padding-bottom: 10px;">
        <div class="container" style="max-width: 768px;">
            <h1 class="text-center">Circumventing Concept Erasure Methods in Text-to-Image Models</h1>
        </div>
        <div class="container" style="max-width: 768px;">
            <div class="row authors">
                
                <div class="col-sm-3 offset-sm-1">
                    <h5 class="text-center"><a href="https://www.mnpham.com/">Minh Pham</a></h5>
                    <h6 class="text-center">New York University</h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center"><a class="text-center" href="https://km3888.github.io/">Kelly Marshall</a></h5>
                    <h6 class="text-center">New York University</h6>
                </div>
                <div class="col-sm-3">
                    <h5 class="text-center"><a href="https://chinmayhegde.github.io/">Chinmay Hegde</a></h5>
                    <h6 class="text-center">New York University</h6>
                </div>
            </div>
        </div>
        <div style="display: flex; justify-content: center;">
            <div class="buttons" style="margin-bottom: 8px;">
                <a class="btn btn-light" role="button" href="https://arxiv.org/abs/2306.08183" target="_blank">
                    <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">
                        <path fill="currentColor" d="M16 0H8C6.9 0 6 .9 6 2V18C6 19.1 6.9 20 8 20H20C21.1 20 22 19.1 22 18V6L16 0M20 18H8V2H15V7H20V18M4 4V22H20V24H4C2.9 24 2 23.1 2 22V4H4M10 10V12H18V10H10M10 14V16H15V14H10Z"></path>
                    </svg>Paper
                </a>
                <a class="btn btn-light" role="button" href="https://github.com/NYU-DICE-Lab/circumventing-concept-erasure">
                    <svg style="width:24px;height:24px;margin-left:-12px;margin-right:12px" viewBox="0 0 24 24">
                        <path fill="currentColor" d="M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z"></path>
                    </svg>
                    Code
                </a>
            </div>
        </div>
    </div>

    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Abstract</h2>
                <p>
                    <!-- <strong> -->
                        Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. On the flip side, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to "erase" sensitive concepts from text-to-image models. In this work, we examine five recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we leverage the existence of special learned word embeddings that can retrieve "erased" concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety. <p style="color:red;"><b>Warning</b>: Some results may appear offensive to readers. </p>
                    <!-- </strong> -->
                </p>
            </div>
        </div>
       
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div style="display: flex; justify-content: center;">
                <img src="/CCE/docs/assets/headline.png" alt="Headline Figure" style="max-width: 100%; height: auto;">
            </div>
        </div>
    </div>
    
   
    <hr class="divider" />
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Why concept erasure is important?</h2>
                <p>
                    Over the last 18 months, text-to-image models have garnered significant attention due to their exceptional ability to synthesize high-quality images based on textual prompts. In particular, the open-sourcing of Stable Diffusion has democratized the landscape of image generation technology. This shift underlines the growing potential and practical relevance of these models in diverse real-world applications. However, despite their burgeoning popularity, these models come with serious caveats. They have been shown to produce copyrighted, unauthorized, biased, and potentially unsafe content. This raises serious for the general public whose unfettered use of these tools has opened up the possibility for a wide range of detriments. At one end of the user spectrum, outputs of generative image models can lead to data privacy violations and copyright infringement. On the other end of the user spectrum, uncontrolled outputs of such models can easily result to harmful, offensive, and NSFW content.
                </p>
            </div>
        </div>
    </div>
    <div class="container" style="max-width: 768px;">
        <div class="row">
            <div class="col-md-12">
                <h2>Do current concept erasure methods really work?</h2>
                <p>
                    The <b>short</b> answer is: Yes. <br>
                    The <b>long</b> answer is: Not really. The erased models only prevent generation of images with the targeted concepts for certain prompts. In particular, we can learn special word embeddings that can retrieve  the so-called "erased" concepts from the sanitized models, and this is done without making any modifications to their existing weights. <br><br>
                    We investigated 5 current concept erasure methods, namely namely <a href="https://erasing.baulab.info" target="_blank">Erased Stable Diffusion (ESD)</a>,  <a href="https://arxiv.org/abs/2303.17591" target="_blank">Forget-Me-Not (FMN)</a>, <a href="https://arxiv.org/abs/2305.10120" target="_blank">Selective Amnesia (SA)</a>, <a href="https://arxiv.org/abs/2211.05105" target="_blank">Safe Latent Diffusion (SLD)</a>, and Negative Prompt (NP). Our results demonstrated our ability to retrieve the "erased" concepts across four distinctive categories: Object, Identity, Art, and NSFW content.  <br><br>
                </p>
                <h4>Art</h4><br>
                <div class="row">
                    <div style="display: flex; justify-content: center;">
                        <figure>
                            <img src="/CCE/docs/assets/ci_art_1.png" alt="CI Art 1" style="max-width: 100%; height: auto;">
                            <figcaption style="text-align: center;"><b>Concept Inversion (CI) on ESD, Negative Prompt and Forget-Me-Not for art concept. </b> The first three columns demonstrate the effectiveness of concept erasure methods when using the prompt: "a painting in the style of [<i>artist name</i>]". However, when we replace [<i>artist name</i>] with the special token learned by Concept Inversion, the model can still generate images of the erased styles.</figcaption>
                        </figure>
                    </div>
                </div>
                <br>
                <div class="row">
                    <div style="display: flex; justify-content: center;">
                        <figure>
                            <img src="/CCE/docs/assets/ci_art_2.png" alt="CI Art 2" style="max-width: 100%; height: auto;">
                            <figcaption style="text-align: center;"><b>Concept Inversion (CI) on SLD for art concept.</b>  Columns 2 to 5 demonstrate the effectiveness of erasing artistic styles for each SLD variant. Concept Inversion can recover the style most consistently for SLD-Weak and SLD-Strong. In some cases, we can observe recovery for even SLD-Strong.</figcaption>
                        </figure>
                    </div>
                </div>
                <br><br>
                <h4>Identity</h4><br>
                <div class="row">
                    <div style="display: flex; justify-content: center;">
                        <figure>
                            <img src="/CCE/docs/assets/ci_id.png" alt="CI ID" style="max-width: 100%; height: auto;">
                            <figcaption style="text-align: center;"><b>Concept Inversion (CI) on Selective Amnesia and Forget-Me-Not for ID concept.</b> Selective Amnesia aims to map concepts such as Brad Pitt and Angelina Jolie to images of middle-aged people and clowns. The first row demonstrates the effectiveness of the algorithm when using the prompt: "a photo portrait of [<i>person name</i>]". However, when we replace <i>person name</i> with a pseudo-word associated with the learned word embedding, the model can still generate images of the erased concepts.</figcaption>
                        </figure>
                    </div>
                </div>
                <br><br>
                <h4>Object</h4><br>
                    <div style="display: flex; justify-content: center;">
                        <figure>
                            <img src="/CCE/docs/assets/ci_object.png" alt="CI Object" style="max-width: 100%; height: auto;">
                            <figcaption style="text-align: center;"><b>Concept Inversion (CI) on ESD for ImageNet.</b> The second row demonstrates the effectiveness of ESD. However, Concept Inversion can recover the objects as shown in the third row.</figcaption>
                        </figure>
                    </div>
                <br><br>
                <h4>NSFW Content</h4><br>
                    <div style="display: flex; justify-content: center;">
                        <figure>
                            <img src="/CCE/docs/assets/ci_nsfw.png" alt="CI NSFW" style="max-width: 100%; height: auto;">
                            <figcaption style="text-align: center;"><b>Concept Inversion (CI) on NSFW concept for I2P dataset.</b> Although all concept erasure techniques effectively decrease the count of detected exposed body parts, Concept Inversion can elevate this number, surpassing even those detected in images generated by Stable Diffusion 1.4.</figcaption>
                        </figure>
                    </div>
            </div>
        </div>
    </div>
</div>
<div class="container" style="max-width: 768px;">
    <div class="row">
        <div class="col-md-12">

            <div class="col-md-12">
                <h2>Citation</h2>
                <code>
                    @misc{marshall2023zeroforge,<br>
                        title={ZeroForge: Feedforward Text-to-Shape Without 3D Supervision}, <br>
                        author={Kelly O. Marshall and Minh Pham and Ameya Joshi and Anushrut Jignasu <br> and Aditya Balu and Adarsh Krishnamurthy and Chinmay Hegde},<br>
                        year={2023},<br>
                        eprint={2306.08183}, <br>
                        archivePrefix={arXiv}, <br>
                        primaryClass={cs.CV} <br>
}
                </code>
            </div>
        </div>
</div>
<hr class="divider" />

    <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
    <script src="/assets/js/yall.js"></script>
    <script>
        yall(
            {
                observeChanges: true
            }
        );
    </script>
    <script src="/assets/js/scripts.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>
    <!-- Import the component -->
</body>

</html>